{"metadata":{"kernelspec":{"display_name":"Python [conda env:Clustering]","language":"python","name":"conda-env-Clustering-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/manishkr1754/diabetes-prediction?scriptVersionId=142553674\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"---\n<center><h1>Diabetes Prediction</h1></center>\n<center><h3>Part of 30 Days 30 ML Projects Challenge</h3></center>\n\n---","metadata":{}},{"cell_type":"markdown","source":"## 1) Understanding Problem Statement\n---\n\n**Diabetes** is a chronic medical condition that affects how your body processes glucose (sugar) in the blood. It occurs when either the pancreas doesn't produce enough insulin (a hormone that regulates blood sugar) or when the body can't effectively use the insulin it produces. This results in elevated blood sugar levels, which can lead to various health complications if not managed properly.\n\nThe goal of this project is to leverage machine learning **to predict whether an individual has diabetes or not based on certain medical variables**. This falls under **Classication Machine Learning Problem**. This prediction can be valuable for early diagnosis and intervention which can improve the management of diabetes.","metadata":{}},{"cell_type":"markdown","source":"## 2) Understanding Data\n---\nThe project uses Diabetes data which contains several medical variables (independent variables) and one outcome variable (dependent variable) for each individual.\n\n### Dataset Description:\n\n- **Pregnancies:** The number of times a woman has been pregnant.\n- **Glucose:** Plasma glucose concentration measured 2 hours after an oral glucose tolerance test.\n- **BloodPressure:** Diastolic blood pressure (in mmHg).\n- **SkinThickness:** Triceps skin fold thickness (in mm).\n- **Insulin:** 2-hour serum insulin level (in Î¼U/ml).\n- **BMI (Body Mass Index):** A measure of body fat based on weight in kilograms divided by height in meters squared.\n- **Age:** The age of the individual in years.\n- **DiabetesPedigreeFunction:** A score that indicates the likelihood of diabetes based on family history.\n- **Outcome:** The outcome variable with two possible values:\n  - 0: Indicates that the individual does not have diabetes.\n  - 1: Indicates that the individual has diabetes.\n","metadata":{}},{"cell_type":"markdown","source":"## 3) Getting System Ready\n---\nImporting required libraries\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# for model buidling\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4) Data Eyeballing\n---","metadata":{}},{"cell_type":"markdown","source":"### Laoding Data","metadata":{}},{"cell_type":"code","source":"diabetes_data = pd.read_csv('Datasets/Day2_Diabetes_Data.csv') ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabetes_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The size of Dataframe is: ', diabetes_data.shape)\nprint('-'*100)\nprint('The Column Name, Record Count and Data Types are as follows: ')\ndiabetes_data.info()\nprint('-'*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining numerical & categorical columns\nnumeric_features = [feature for feature in diabetes_data.columns if diabetes_data[feature].dtype != 'O']\ncategorical_features = [feature for feature in diabetes_data.columns if diabetes_data[feature].dtype == 'O']\n\n# print columns\nprint('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\nprint('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Missing Value Presence in different columns of DataFrame are as follows : ')\nprint('-'*100)\ntotal=diabetes_data.isnull().sum().sort_values(ascending=False)\npercent=(diabetes_data.isnull().sum()/diabetes_data.isnull().count()*100).sort_values(ascending=False)\npd.concat([total, percent], axis=1, keys=['Total', 'Percent'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Summary Statistics of numerical features for DataFrame are as follows:')\nprint('-'*100)\ndiabetes_data.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabetes_data.groupby('Outcome').mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabetes_data['Outcome'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### No Data Cleaning and Preprocessing Needed","metadata":{}},{"cell_type":"markdown","source":"## 5) Model Building\n---","metadata":{}},{"cell_type":"markdown","source":"### Creating Feature Matrix (Independent Variables) & Target Variable (Dependent Variable)","metadata":{}},{"cell_type":"code","source":"# separating the data and labels\nX = diabetes_data.drop(columns = 'Outcome', axis=1) # Feature matrix\ny = diabetes_data['Outcome'] # Target variable","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Standardization","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler.fit(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"standardized_data = scaler.transform(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"standardized_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = standardized_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train-Test Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=45)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape, X_train.shape, X_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y.shape, y_train.shape, y_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Comparison : Training & Evaluation","metadata":{}},{"cell_type":"code","source":"models = [LogisticRegression, SVC, DecisionTreeClassifier, RandomForestClassifier]\naccuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\nfor model in models:\n    classifier = model().fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    \n    accuracy_scores.append(accuracy_score(y_test, y_pred))\n    precision_scores.append(precision_score(y_test, y_pred))\n    recall_scores.append(recall_score(y_test, y_pred))\n    f1_scores.append(f1_score(y_test, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classification_metrics_df = pd.DataFrame({\n    \"Model\": [\"Logistic Regression\", \"SVM\", \"Decision Tree\", \"Random Forest\"],\n    \"Accuracy\": accuracy_scores,\n    \"Precision\": precision_scores,\n    \"Recall\": recall_scores,\n    \"F1 Score\": f1_scores\n})\n\nclassification_metrics_df.set_index('Model', inplace=True)\nclassification_metrics_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\nBest Model based on accuracy score only is Random Forest Classifier. However, for real life best model selection are not solely based on accuracy score, we need to take into account other evaluation metrics, business context and model interpretability.\n\nThe choice of the best model may depend on factors like the balance between precision and recall as well as overall accuracy. In this context, where the primary goal is to predict whether an individual has diabetes or not, the choice of the best model should prioritize predictive accuracy and reliability.\n\n- Based on the provided metrics and considering the goal of accurately predicting diabetes, the **SVM (Support Vector Machine) model** appears to perform the best. It has the highest accuracy, precision and F1 score among the models you've evaluated.\n\n- **Logistic Regression** and **Random Forest** also perform well and could be considered as alternatives.\n\n\n**`Note:`** For real life best model selection are not solely based on accuracy score, we need to take into account other evaluation metrics, business context and model interpretability.","metadata":{}}]}
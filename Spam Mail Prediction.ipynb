{"metadata":{"kernelspec":{"display_name":"Python [conda env:NLP39]","language":"python","name":"conda-env-NLP39-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/manishkr1754/spam-mail-prediction?scriptVersionId=144421269\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"---\n<center><h1>Spam Mail Prediction</h1></center>\n<center><h3>Part of 30 Days 30 ML Projects Challenge</h3></center>\n\n---","metadata":{}},{"cell_type":"markdown","source":"## 1) Understanding Problem Statement\n---\n\nIn the age of digital communication, spam emails have become a significant nuisance, cluttering inboxes and potentially causing harm. This project addresses the issue of spam email detection through the lens of machine learning and data science.\n\nThe problem at hand falls into the category of **Binary Classification Machine Learning Problem**. The central objective is **to create a predictive model capable of distinguishing between spam and legitimate emails**. This model will rely on various email attributes and content features to make informed predictions, ultimately helping users filter out unwanted and potentially harmful messages. Moreover, It also involves use of **Natural Language Processing (NLP)** techniques for handling textual data.","metadata":{}},{"cell_type":"markdown","source":"## 2) Understanding Data\n---\n\nThe project uses **Mail Data** which contains several variables (independent variables) and the outcome variable or dependent variable.","metadata":{}},{"cell_type":"markdown","source":"## 3) Getting System Ready\n---\nImporting required libraries\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# for text data preprocessing\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# for model buidling\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Downloading stop words for text preprocessing","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# printing the stopwords in English\nprint(stopwords.words('english'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4) Data Eyeballing\n---","metadata":{}},{"cell_type":"markdown","source":"### Laoding Data","metadata":{}},{"cell_type":"code","source":"mail_data = pd.read_csv('Datasets/Day17_Mail_Data.csv') ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mail_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The size of Dataframe is: ', mail_data.shape)\nprint('-'*100)\nprint('The Column Name, Record Count and Data Types are as follows: ')\nmail_data.info()\nprint('-'*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining numerical & categorical columns\nnumeric_features = [feature for feature in mail_data.columns if mail_data[feature].dtype != 'O']\ncategorical_features = [feature for feature in mail_data.columns if mail_data[feature].dtype == 'O']\n\n# print columns\nprint('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\nprint('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Missing Value Presence in different columns of DataFrame are as follows : ')\nprint('-'*100)\ntotal=mail_data.isnull().sum().sort_values(ascending=False)\npercent=(mail_data.isnull().sum()/mail_data.isnull().count()*100).sort_values(ascending=False)\npd.concat([total, percent], axis=1, keys=['Total', 'Percent'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Summary Statistics of numerical features for DataFrame are as follows:')\nprint('-'*100)\nmail_data.describe(include='object')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) Data Cleaning and Preprocessing\n---","metadata":{}},{"cell_type":"markdown","source":"### Replace the null values with a null string (Only for demonstration, here it is not neede)","metadata":{}},{"cell_type":"code","source":"mail_data = mail_data.where((pd.notnull(mail_data)),'')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mail_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label Encoding","metadata":{}},{"cell_type":"markdown","source":"#### label spam mail as 0;  ham mail as 1;","metadata":{}},{"cell_type":"code","source":"mail_data.loc[mail_data['Category'] == 'spam', 'Category',] = 0\nmail_data.loc[mail_data['Category'] == 'ham', 'Category',] = 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mail_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mail_data['Category'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stemming","metadata":{}},{"cell_type":"code","source":"porter_stemmer = PorterStemmer()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stemming(content):\n    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n    stemmed_content = stemmed_content.lower()\n    stemmed_content = stemmed_content.split()\n    stemmed_content = [porter_stemmer.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n    stemmed_content = ' '.join(stemmed_content)\n    return stemmed_content","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mail_data['Message'] = mail_data['Message'].apply(stemming)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mail_data['Message']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6) Model Building\n---","metadata":{}},{"cell_type":"markdown","source":"### Creating Feature Matrix (Independent Variables) & Target Variable (Dependent Variable)","metadata":{}},{"cell_type":"code","source":"# separating the data and labels\nX = mail_data['Message'] # Feature matrix\ny = mail_data['Category'] # Target variable","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert Y_train and Y_test values as integers\ny = y.astype('int')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Extraction","metadata":{}},{"cell_type":"markdown","source":"#### Transform the text data to feature vectors that can be used as input to the Logistic regression","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer.fit(X)\n\nX = vectorizer.transform(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train-Test Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=45)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape, X_train.shape, X_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y.shape, y_train.shape, y_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Comparison : Training & Evaluation","metadata":{}},{"cell_type":"code","source":"models = [LogisticRegression, SVC, DecisionTreeClassifier, RandomForestClassifier]\naccuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\nfor model in models:\n    classifier = model().fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    \n    accuracy_scores.append(accuracy_score(y_test, y_pred))\n    precision_scores.append(precision_score(y_test, y_pred))\n    recall_scores.append(recall_score(y_test, y_pred))\n    f1_scores.append(f1_score(y_test, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classification_metrics_df = pd.DataFrame({\n    \"Model\": [\"Logistic Regression\", \"SVM\", \"Decision Tree\", \"Random Forest\"],\n    \"Accuracy\": accuracy_scores,\n    \"Precision\": precision_scores,\n    \"Recall\": recall_scores,\n    \"F1 Score\": f1_scores\n})\n\nclassification_metrics_df.set_index('Model', inplace=True)\nclassification_metrics_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n\nIn the context of spam mail prediction, the performance metrics of four different models—Logistic Regression, SVM, Decision Tree, and Random Forest—have been evaluated. \n\n- Overall, all models exhibit high accuracy, with SVM and Random Forest leading the way, achieving accuracy scores of approximately 97.22% and 97.49%, respectively. This suggests that these models are effective at correctly classifying emails as spam or legitimate.\n\n- When considering precision, recall, and F1 Score, the SVM and Random Forest models again excel, with precision scores exceeding 96.89% and recall scores reaching 100%, indicating minimal false positives and false negatives. Decision Tree also performs well in terms of precision and recall.\n\nIn summary, SVM and Random Forest models stand out as strong contenders for spam mail prediction, with high accuracy, precision, and recall scores. However, the choice of the best model may also depend on specific requirements such as computational efficiency and interpretability.","metadata":{}}]}
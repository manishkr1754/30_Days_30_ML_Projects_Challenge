{"metadata":{"kernelspec":{"display_name":"Python [conda env:Clustering]","language":"python","name":"conda-env-Clustering-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/manishkr1754/loan-eligibility-prediction?scriptVersionId=142889708\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"---\n<center><h1>Loan Eligibility Prediction</h1></center>\n<center><h3>Part of 30 Days 30 ML Projects Challenge</h3></center>\n\n---","metadata":{}},{"cell_type":"markdown","source":"## 1) Understanding Problem Statement\n---\n\nThe Finance company faces the challenge of accurately predicting loan eligibility for its customers. In order to make informed lending decisions and minimize risk, the company needs to develop a robust predictive model that takes into account various factors and attributes of the applicants. This predictive model will help the Finance company streamline its lending processes, reduce the likelihood of default and ensure fair and transparent loan approval practices, ultimately improving the overall efficiency and profitability of the company's operations.\n\nThe project falls under **Classication Machine Learning Problem**. The goal of this project is to leverage machine learning **to determine whether an applicant is eligible for a loan or not** while also considering factors such as credit history, income, employment status and other relevant variables.","metadata":{}},{"cell_type":"markdown","source":"## 2) Understanding Data\n---\nThe project uses Loan Prediction Data which contains several variables (independent variables) like **Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others** and one outcome variable (dependent variable) called **Loan Status** for each individual.\n\n- **Loan Status:** The outcome variable with two possible values:\n  - Y: Indicates that the individual is eligible for Loan.\n  - N: Indicates that the individual is not eligible for Loan.","metadata":{}},{"cell_type":"markdown","source":"## 3) Getting System Ready\n---\nImporting required libraries\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# for model buidling\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4) Data Eyeballing\n---","metadata":{}},{"cell_type":"markdown","source":"### Laoding Data","metadata":{}},{"cell_type":"code","source":"loan_data = pd.read_csv('Datasets/Day5_Loan_Prediction_Data.csv') ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loan_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The size of Dataframe is: ', loan_data.shape)\nprint('-'*100)\nprint('The Column Name, Record Count and Data Types are as follows: ')\nloan_data.info()\nprint('-'*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining numerical & categorical columns\nnumeric_features = [feature for feature in loan_data.columns if loan_data[feature].dtype != 'O']\ncategorical_features = [feature for feature in loan_data.columns if loan_data[feature].dtype == 'O']\n\n# print columns\nprint('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\nprint('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Missing Value Presence in different columns of DataFrame are as follows : ')\nprint('-'*100)\ntotal=loan_data.isnull().sum().sort_values(ascending=False)\npercent=(loan_data.isnull().sum()/loan_data.isnull().count()*100).sort_values(ascending=False)\npd.concat([total, percent], axis=1, keys=['Total', 'Percent'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Summary Statistics of numerical features for DataFrame are as follows:')\nprint('-'*100)\nloan_data.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Summary Statistics of categorical features for DataFrame are as follows:')\nprint('-'*100)\nloan_data.describe(include='object')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loan_data['Loan_Status'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) Data Cleaning and Preprocessing\n---","metadata":{}},{"cell_type":"markdown","source":"### Dropping the missing values","metadata":{}},{"cell_type":"code","source":"loan_data = loan_data.dropna()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Missing Value Presence in different columns of DataFrame are as follows : ')\nprint('-'*100)\ntotal=loan_data.isnull().sum().sort_values(ascending=False)\npercent=(loan_data.isnull().sum()/loan_data.isnull().count()*100).sort_values(ascending=False)\npd.concat([total, percent], axis=1, keys=['Total', 'Percent'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label Encoding","metadata":{}},{"cell_type":"code","source":"loan_data.replace({\"Loan_Status\":{'N':0,'Y':1}},inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loan_data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Processinng `Dependent` column","metadata":{}},{"cell_type":"code","source":"loan_data['Dependents'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing the value of 3+ to 4\nloan_data = loan_data.replace(to_replace='3+', value=4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loan_data['Dependents'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Converting categorical columns to numerical values","metadata":{}},{"cell_type":"code","source":"# convert categorical columns to numerical values\nloan_data.replace({'Married':{'No':0,'Yes':1},'Gender':{'Male':1,'Female':0},'Self_Employed':{'No':0,'Yes':1},\n                      'Property_Area':{'Rural':0,'Semiurban':1,'Urban':2},'Education':{'Graduate':1,'Not Graduate':0}},inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loan_data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) Model Building\n---","metadata":{}},{"cell_type":"markdown","source":"### Creating Feature Matrix (Independent Variables) & Target Variable (Dependent Variable)","metadata":{}},{"cell_type":"code","source":"# separating the data and labels\nX = loan_data.drop(columns = ['Loan_ID','Loan_Status'], axis=1) # Feature matrix\ny = loan_data['Loan_Status'] # Target variable","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Standardization","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler.fit(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"standardized_data = scaler.transform(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"standardized_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = standardized_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train-Test Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=45)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape, X_train.shape, X_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y.shape, y_train.shape, y_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Comparison : Training & Evaluation","metadata":{}},{"cell_type":"code","source":"models = [LogisticRegression, SVC, DecisionTreeClassifier, RandomForestClassifier]\naccuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\nfor model in models:\n    classifier = model().fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    \n    accuracy_scores.append(accuracy_score(y_test, y_pred))\n    precision_scores.append(precision_score(y_test, y_pred))\n    recall_scores.append(recall_score(y_test, y_pred))\n    f1_scores.append(f1_score(y_test, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classification_metrics_df = pd.DataFrame({\n    \"Model\": [\"Logistic Regression\", \"SVM\", \"Decision Tree\", \"Random Forest\"],\n    \"Accuracy\": accuracy_scores,\n    \"Precision\": precision_scores,\n    \"Recall\": recall_scores,\n    \"F1 Score\": f1_scores\n})\n\nclassification_metrics_df.set_index('Model', inplace=True)\nclassification_metrics_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\nIn the context of Loan Eligibility Prediction:\n\n1. **Logistic Regression** demonstrates the highest recall (0.97) indicating its effectiveness in identifying eligible applicants. However, precision (0.75) and F1 score (0.85) show a trade-off between accuracy and false positives.\n\n2. **SVM** maintains a high recall (0.95) with a slightly lower precision (0.75). It's a balanced choice for minimizing false negatives while controlling false positives.\n\n3. **Decision Tree** has the lowest accuracy (0.65) among the models. It provides good precision (0.75) but struggles with recall (0.73) leading to a moderate F1 score (0.74).\n\n4. **Random Forest** strikes a balance between precision (0.77) and recall (0.89) resulting in a reasonable F1 score (0.83) and overall accuracy (0.74).\n\nIn summary, Logistic Regression excels in recall but sacrifices precision. SVM offers a balanced approach while Random Forest strikes a compromise between precision and recall.\n\n\n**`Note:`** Choosing the most suitable model depends on the specific objectives of the Finance company. If minimizing false negatives (approving loans for eligible applicants) is crucial, Logistic Regression or SVM may be preferred. If a balance between precision and recall is desired, Random Forest offers a reasonable compromise. Further model evaluation and fine-tuning may be necessary to optimize performance for the specific business goals.","metadata":{}}],"kernelspec":{"display_name":"Python [conda env:Clustering]","language":"python","name":"conda-env-Clustering-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}}
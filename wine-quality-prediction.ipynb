{"metadata":{"kernelspec":{"display_name":"Python [conda env:Clustering]","language":"python","name":"conda-env-Clustering-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\n<center><h1>Wine Quality Prediction</h1></center>\n<center><h3>Part of 30 Days 30 ML Projects Challenge</h3></center>\n\n---","metadata":{}},{"cell_type":"markdown","source":"## 1) Understanding Problem Statement\n---\n\nWine is a complex and diverse beverage that is enjoyed worldwide. The quality of wine is influenced by numerous factors such as grape variety, climate, soil conditions and winemaking techniques. Accurately assessing wine quality is essential for both producers and consumers. While traditional methods rely on human experts and sensory evaluations, machine learning models can provide valuable insights and predictions based on objective data. \n\nThe project falls under **Classication Machine Learning Problem**. The goal of this project is **to develop a wine quality prediction model to predict the quality of wine based on various chemical and physical attributes.","metadata":{}},{"cell_type":"markdown","source":"## 2) Understanding Data\n---\n\nThe project uses Wine Quality Data which contains several variables (independent variables) such as **acidity, alcohol content, density, pH and more.** The outcome variable or dependent variable is the **quality** score which ranges from 0 to 10 and is based on sensory data. The quality score serves as the ground truth for training and evaluating the predictive model.\n\nThe dataset encompasses **11 independent variables** each representing a specific aspect of wine composition and the 12th variable, **quality**, quantifying the overall perceived quality of the wine which are shown as follows: \n\n- 1. fixed acidity\n- 2. volatile acidity\n- 3. citric acid\n- 4. residual sugar\n- 5. chlorides\n- 6. free sulfur dioxide\n- 7. total sulfur dioxide\n- 8. density\n- 9. pH\n- 10. sulphates\n- 11. alcohol\n- 12. quality (score between 0 and 10)","metadata":{}},{"cell_type":"markdown","source":"## 3) Getting System Ready\n---\nImporting required libraries\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# for model buidling\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4) Data Eyeballing\n---","metadata":{}},{"cell_type":"markdown","source":"### Laoding Data","metadata":{}},{"cell_type":"code","source":"wine_data = pd.read_csv('Datasets/Day6_Wine_Quality_Data.csv') ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wine_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The size of Dataframe is: ', wine_data.shape)\nprint('-'*100)\nprint('The Column Name, Record Count and Data Types are as follows: ')\nwine_data.info()\nprint('-'*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining numerical & categorical columns\nnumeric_features = [feature for feature in wine_data.columns if wine_data[feature].dtype != 'O']\ncategorical_features = [feature for feature in wine_data.columns if wine_data[feature].dtype == 'O']\n\n# print columns\nprint('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\nprint('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Missing Value Presence in different columns of DataFrame are as follows : ')\nprint('-'*100)\ntotal=wine_data.isnull().sum().sort_values(ascending=False)\npercent=(wine_data.isnull().sum()/wine_data.isnull().count()*100).sort_values(ascending=False)\npd.concat([total, percent], axis=1, keys=['Total', 'Percent'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Summary Statistics of numerical features for DataFrame are as follows:')\nprint('-'*100)\nwine_data.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wine_data['quality'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) Data Cleaning and Preprocessing\n---","metadata":{}},{"cell_type":"markdown","source":"### Label Binarization (0 or 1)","metadata":{}},{"cell_type":"code","source":"wine_data['quality'] = wine_data['quality'].apply(lambda y_value: 1 if y_value >= 7 else 0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wine_data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) Model Building\n---","metadata":{}},{"cell_type":"markdown","source":"### Creating Feature Matrix (Independent Variables) & Target Variable (Dependent Variable)","metadata":{}},{"cell_type":"code","source":"# separating the data and labels\nX = wine_data.drop(columns = ['quality'], axis=1) # Feature matrix\ny = wine_data['quality'] # Target variable","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Standardization","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler.fit(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"standardized_data = scaler.transform(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"standardized_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = standardized_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train-Test Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=45)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape, X_train.shape, X_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y.shape, y_train.shape, y_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Comparison : Training & Evaluation","metadata":{}},{"cell_type":"code","source":"models = [LogisticRegression, SVC, DecisionTreeClassifier, RandomForestClassifier]\naccuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\nfor model in models:\n    classifier = model().fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    \n    accuracy_scores.append(accuracy_score(y_test, y_pred))\n    precision_scores.append(precision_score(y_test, y_pred))\n    recall_scores.append(recall_score(y_test, y_pred))\n    f1_scores.append(f1_score(y_test, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classification_metrics_df = pd.DataFrame({\n    \"Model\": [\"Logistic Regression\", \"SVM\", \"Decision Tree\", \"Random Forest\"],\n    \"Accuracy\": accuracy_scores,\n    \"Precision\": precision_scores,\n    \"Recall\": recall_scores,\n    \"F1 Score\": f1_scores\n})\n\nclassification_metrics_df.set_index('Model', inplace=True)\nclassification_metrics_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n\nIn the context of Wine Quality Prediction, four machine learning models were evaluated: Logistic Regression, SVM, Decision Tree and Random Forest. Among these, **Random Forest performed the best** with the highest accuracy of 92.50% and a respectable F1 score of 68.42%. It excelled in precision, making it reliable in identifying high-quality wines. However, **all models struggled with recall**, indicating potential difficulties in recognizing all high-quality wines. Decision Tree exhibited a balanced trade-off between precision and recall, making it a strong contender for practical applications. The choice of model should align with the specific objectives, emphasizing precision (Random Forest) or comprehensive identification (Decision Tree) of high-quality wines.\n\n**`Note:`** The choice of model should align with the specific objectives, emphasizing precision (Random Forest) or comprehensive identification (Decision Tree) of high-quality wines. Further model evaluation and fine-tuning may be necessary to optimize performance for the specific business goals.","metadata":{}}],"kernelspec":{"display_name":"Python [conda env:Clustering]","language":"python","name":"conda-env-Clustering-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}}
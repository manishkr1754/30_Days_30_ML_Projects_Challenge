{"metadata":{"kernelspec":{"display_name":"Python [conda env:Clustering]","language":"python","name":"conda-env-Clustering-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/manishkr1754/breast-cancer-classification?scriptVersionId=144981123\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"---\n<center><h1>Breast Cancer Classification</h1></center>\n<center><h3>Part of 30 Days 30 ML Projects Challenge</h3></center>\n\n---","metadata":{}},{"cell_type":"markdown","source":"## 1) Understanding Problem Statement\n---\n\nBreast cancer is a widespread and potentially life-threatening medical condition that affects a significant portion of the population, predominantly women. Timely and precise diagnosis of breast cancer plays a crucial role in determining treatment options and improving patient outcomes. In this context, the application of machine learning offers a promising avenue to tackle this healthcare challenge.\n\nThis project belongs to the domain of **Medical Diagnosis and Classification using Machine Learning**. The primary goal is **to develop a predictive model for the classification of breast cancer by analyzing a comprehensive dataset that includes various clinical attributes, mammography findings and patient demographics**.","metadata":{}},{"cell_type":"markdown","source":"## 2) Understanding Data\n---\n\nThe project uses **Breast Cancer Data** which contains several variables (independent variables) and the outcome variable or dependent variable.","metadata":{}},{"cell_type":"markdown","source":"## 3) Getting System Ready\n---\nImporting required libraries\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# for model buidling\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4) Data Eyeballing\n---","metadata":{}},{"cell_type":"markdown","source":"### Laoding Data","metadata":{}},{"cell_type":"code","source":"breast_cancer_data = pd.read_csv('Datasets/Day19_Breast_Cancer_Data.csv') ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breast_cancer_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The size of Dataframe is: ', breast_cancer_data.shape)\nprint('-'*100)\nprint('The Column Name, Record Count and Data Types are as follows: ')\nbreast_cancer_data.info()\nprint('-'*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining numerical & categorical columns\nnumeric_features = [feature for feature in breast_cancer_data.columns if breast_cancer_data[feature].dtype != 'O']\ncategorical_features = [feature for feature in breast_cancer_data.columns if breast_cancer_data[feature].dtype == 'O']\n\n# print columns\nprint('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\nprint('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Missing Value Presence in different columns of DataFrame are as follows : ')\nprint('-'*100)\ntotal=breast_cancer_data.isnull().sum().sort_values(ascending=False)\npercent=(breast_cancer_data.isnull().sum()/breast_cancer_data.isnull().count()*100).sort_values(ascending=False)\npd.concat([total, percent], axis=1, keys=['Total', 'Percent'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Summary Statistics of numerical features for DataFrame are as follows:')\nprint('-'*100)\nbreast_cancer_data.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Summary Statistics of categorical features for DataFrame are as follows:')\nprint('-'*100)\nbreast_cancer_data.describe(include='object')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breast_cancer_data['diagnosis'].value_counts() # status is target variable","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) Data Cleaning and Preprocessing\n---","metadata":{}},{"cell_type":"markdown","source":"### Dropping unwanted columns","metadata":{}},{"cell_type":"code","source":"breast_cancer_data = breast_cancer_data.drop(columns = ['Unnamed: 32'], axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breast_cancer_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding 'M'(Malignant) as 0 and 'B'(Benign) as 1","metadata":{}},{"cell_type":"code","source":"breast_cancer_data['diagnosis'] = breast_cancer_data['diagnosis'].map({'M':0,'B':1})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breast_cancer_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) Model Building\n---","metadata":{}},{"cell_type":"markdown","source":"### Creating Feature Matrix (Independent Variables) & Target Variable (Dependent Variable)","metadata":{}},{"cell_type":"code","source":"# separating the data and labels\nX = breast_cancer_data.drop(columns = ['id','diagnosis'], axis=1) # Feature matrix\ny = breast_cancer_data['diagnosis'] # Target variable","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Standardization","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler.fit(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"standardized_data = scaler.transform(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"standardized_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = standardized_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train-Test Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=45)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape, X_train.shape, X_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y.shape, y_train.shape, y_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Comparison : Training & Evaluation","metadata":{}},{"cell_type":"code","source":"models = [LogisticRegression, SVC, DecisionTreeClassifier, RandomForestClassifier]\naccuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\nfor model in models:\n    classifier = model().fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    \n    accuracy_scores.append(accuracy_score(y_test, y_pred))\n    precision_scores.append(precision_score(y_test, y_pred))\n    recall_scores.append(recall_score(y_test, y_pred))\n    f1_scores.append(f1_score(y_test, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classification_metrics_df = pd.DataFrame({\n    \"Model\": [\"Logistic Regression\", \"SVM\", \"Decision Tree\", \"Random Forest\"],\n    \"Accuracy\": accuracy_scores,\n    \"Precision\": precision_scores,\n    \"Recall\": recall_scores,\n    \"F1 Score\": f1_scores\n})\n\nclassification_metrics_df.set_index('Model', inplace=True)\nclassification_metrics_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n\nIn the context of breast cancer classification,\n\n- The Logistic Regression and Support Vector Machine (SVM) models demonstrate the highest accuracy at 96.49%, indicating their proficiency in distinguishing between benign (B) and malignant (M) cases. Additionally, both models exhibit impressive precision and recall scores, exceeding 95%, showcasing their ability to minimize false positives and false negatives.\n\n- The Decision Tree model, while achieving a decent accuracy of 91.23%, lags behind in terms of precision and recall, indicating a moderate performance in correctly classifying cases. \n\n- On the other hand, the Random Forest model, with an accuracy of 94.74%, strikes a balance between precision and recall. It achieves a commendable precision score of 97.14%, suggesting a low rate of false positives, while maintaining a good recall score of 94.44%, indicating its effectiveness in detecting malignant cases.\n\nIn conclusion, the Logistic Regression and SVM models exhibit the best overall performance, emphasizing their potential for breast cancer classification. However, the Random Forest model also proves to be a reliable choice with a well-rounded performance. The Decision Tree, while decent, may benefit from further optimization to enhance its predictive capabilities.","metadata":{}}]}